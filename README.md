# Пайплайн обработки данных с использованием Luigi

Данный проект демонстрирует использование Luigi для создания пайплайна обработки данных из базы GEO. 

Пайплайн выполняет следующие шаги:

1. **Скачивание архива с данными**: Загружает `.tar`-архив, содержащий вспомогательные файлы для указанного набора данных.
2. **Распаковка архива**: Извлекает содержимое `.tar`-архива в директорию.
3. **Распаковка GZIP-файлов**: Распаковывает файлы `.gz` из архива.
4. **Разделение таблиц**: Разделяет `.txt`-файлы, содержащие несколько таблиц, на отдельные `.tsv`-файлы.
5. **Удаление ненужных колонок**: Удаляет ненужные колонки из таблиц (например, `Probes.tsv`).

---

## Использование

 **1. Клонирование репозитория**

`git clone <ссылка>`

**2. Установка зависимостей**

`pip install -r requirements.txt`

**3. Запуск пайплайна**

`python main.py pipeline.DatasetPipeline --dataset-name GSE68849 --base-dir ./output --local-scheduler`

Используется команда:

`python main.py pipeline.DatasetPipeline --dataset-name your_dataset_name --base-dir your_base_dir --local-scheduler`

где:
- `your_dataset_name` - имя вашего набора данных в формате .tar-архива, который необходимо распаковать;
- `your_base_dir` - директория, в которой будут сохранены выходные (распакованные) файлы

## Структура выходных данных

```
./output/
├── GSE68849
    ├── decompressed       # Распакованные файлы из архива
    ├── tables             # Таблицы, извлечённые из `.txt`-файлов
    ├── trimmed            # Обработанные таблицы с удалёнными колонками
```